# TAI-EvalGenTCS CLI Configuration
# Copy this file to .env and fill in your values

# ============================================
# OpenRouter API Configuration
# ============================================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter API base URL (usually no need to change)
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# ============================================
# LLM Model Configuration
# ============================================
# Available models (via OpenRouter):
# - openai/gpt-4.1-mini (recommended for balance of cost/quality)
# - openai/gpt-4.1-nano (faster, lower cost)
# - google/gemini-2.5-flash (alternative option)
# - openai/gpt-4-turbo (higher quality, higher cost)
LLM_MODEL=openai/gpt-4.1-mini

# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
# Lower values recommended for code analysis
LLM_TEMPERATURE=0.1

# Maximum tokens for LLM response
LLM_MAX_TOKENS=4000

# ============================================
# Rate Limiting Configuration
# ============================================
# Based on OpenRouter limits: https://openrouter.ai/docs/api-reference/limits
# For credit balance > $15:
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_TOKENS_PER_MINUTE=100000

# ============================================
# Retry Configuration
# ============================================
# Number of retry attempts on API failure
RETRY_ATTEMPTS=3

# Initial delay between retries (seconds)
RETRY_DELAY=2.0

# Backoff factor for exponential backoff
# Delay will be: RETRY_DELAY * (BACKOFF_FACTOR ^ attempt)
BACKOFF_FACTOR=3.0

# ============================================
# Application Configuration
# ============================================
APP_NAME=TAI-EvalGenTCS
APP_VERSION=1.1.0

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
